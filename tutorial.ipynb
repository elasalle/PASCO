{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "626569d5-ba46-49b9-a673-ea8acb24c7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import networkx as nx\n",
    "from pasco.pasco import Pasco\n",
    "from pasco.data_generation import generate_or_import_SBM\n",
    "import numpy as np\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as nmi, adjusted_mutual_info_score as ami, \\\n",
    "    adjusted_rand_score as ari\n",
    "import multiprocessing\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac794f8b-4613-4190-ba56-99d6a991541e",
   "metadata": {},
   "source": [
    "# Create a big graph with a community structure"
   ]
  },
  {
   "cell_type": "raw",
   "id": "95a12b70-2454-4370-a9e6-fd211676ff08",
   "metadata": {},
   "source": [
    "Here, we generate a graph from the Stochastic Block Model. We choose parametrize the model using the average degree and the ratio of inside and outside community probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ff54a80-4a9f-4f90-b6b5-80e591881cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph currently does not exist. We generate it.\n",
      "Graph generated\n"
     ]
    }
   ],
   "source": [
    "n = int(1e4) # number of nodes \n",
    "k = 100  # number of communities \n",
    "d = 1.5 # to set the average degree\n",
    "alpha = 1/(2*(k-1)) # ration of probabilities. Here half the conjectured threshold. See Paper. \n",
    "\n",
    "n_k = n//k # number of nodes per community\n",
    "avg_d = d*np.log(n) # average degree\n",
    "pin = avg_d / ((1 + (k-1) *alpha )*n_k) # inside community edge probability\n",
    "pout = alpha * pin # between communities edge probability\n",
    "\n",
    "\n",
    "partition_true = np.array([i for i in range(k) for j in range(n_k)]) # the true nodes partition\n",
    "G = generate_or_import_SBM(n, k, pin, pout, data_folder=\"experiments/data/graphs/SBMs/\", seed=2024)\n",
    "A = nx.adjacency_matrix(G , nodelist=range(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc333627-7484-4711-953e-f67e3167ca47",
   "metadata": {},
   "source": [
    "# Compute PASCO with Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc7e0e68-19b5-4697-bf90-fa0f1b1c6cc6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m ti \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m      8\u001b[0m pasco \u001b[38;5;241m=\u001b[39m Pasco(k, rho, R, solver\u001b[38;5;241m=\u001b[39msolver)\n\u001b[1;32m----> 9\u001b[0m partition_pasco \u001b[38;5;241m=\u001b[39m \u001b[43mpasco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m tf \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAMI with PASCO+SC : \u001b[39m\u001b[38;5;132;01m{:5.3f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(ami(partition_pasco, partition_true)))\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\PASCO\\pasco\\pasco.py:67\u001b[0m, in \u001b[0;36mPasco.fit_transform\u001b[1;34m(self, A, return_timings)\u001b[0m\n\u001b[0;32m     65\u001b[0m t_cl_i \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m     66\u001b[0m clusterer \u001b[38;5;241m=\u001b[39m Clustering(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk, tables, solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msolver, parallel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel_cl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msolver_args)\n\u001b[1;32m---> 67\u001b[0m partitions \u001b[38;5;241m=\u001b[39m \u001b[43mclusterer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGprimes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m t_cl_f \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m     69\u001b[0m timings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclustering\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m t_cl_f \u001b[38;5;241m-\u001b[39m t_cl_i\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\PASCO\\pasco\\clustering.py:104\u001b[0m, in \u001b[0;36mClustering.fit_transform\u001b[1;34m(self, graphs)\u001b[0m\n\u001b[0;32m    100\u001b[0m cpu_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(mp\u001b[38;5;241m.\u001b[39mcpu_count(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_tables)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mp\u001b[38;5;241m.\u001b[39mPool(cpu_count) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;66;03m# res_async = pool.map_async(self._apply_clustering, graphs)\u001b[39;00m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;66;03m# coarsened_clusterings = res_async.get()\u001b[39;00m\n\u001b[1;32m--> 104\u001b[0m     coarsened_clusterings \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_clustering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraphs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m     args \u001b[38;5;241m=\u001b[39m ((coarsened_clusterings[i], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtables[i], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\n\u001b[0;32m    106\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_tables))\n\u001b[0;32m    107\u001b[0m     partitions \u001b[38;5;241m=\u001b[39m pool\u001b[38;5;241m.\u001b[39mstarmap(coarsened_to_full, args)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\pasco\\Lib\\multiprocessing\\pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[1;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    363\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\pasco\\Lib\\multiprocessing\\pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 768\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[0;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\pasco\\Lib\\multiprocessing\\pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\pasco\\Lib\\threading.py:655\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    653\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 655\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\pasco\\Lib\\threading.py:355\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 355\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    356\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_cpu = multiprocessing.cpu_count()\n",
    "\n",
    "rho = 10 # reduction factor (the coarsened graph will have a size rho times smaller)\n",
    "R = 5 # number of repetitions of the coarsening. R should be kept below the number of CPUs so that all clusterings can be computed in one batch.\n",
    "solver = \"SC\" # we use SC to compute the partition of the coarsened graphs.\n",
    "\n",
    "ti = time()\n",
    "pasco = Pasco(k, rho, R, solver=solver)\n",
    "partition_pasco = pasco.fit_transform(A)\n",
    "tf = time()\n",
    "\n",
    "print(\"AMI with PASCO+SC : {:5.3f}\".format(ami(partition_pasco, partition_true)))\n",
    "print(\"Computation time: {:5.3f}sec\".format((tf-ti)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61db1f40-e6b3-4c10-a575-2b682b1e571d",
   "metadata": {},
   "source": [
    "# How to use PASCO with your own clustering algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae709c91-850e-4751-a0ba-57a4519f80ac",
   "metadata": {},
   "source": [
    "We show here how to use PASCO with a clustering algorithm that would not be implemented in the PASCO package. \\\n",
    "Here we are going to do as if SC was not implemented in PASCO. \n",
    "\n",
    "To do so, we need to create a proxy function. It should take as input a sparse csr_array and potentially a number of clusters $k$ and returns a partition as an array-like. We defined in the `tutorial_utils.py` file a clustering function `my_clustering(A,k)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2d757d-9ec9-4185-b5ee-ba7e8cb55a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tutorial_utils import my_clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcae116-40c9-4d27-9e72-68ed90920838",
   "metadata": {},
   "source": [
    "Now we can use our function `my_clustering` and pass it to the `solver` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e01ed3-f14a-48d2-ad56-aa974f713542",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = my_clustering # clustering is computed using `my_clustering`\n",
    "\n",
    "ti = time()\n",
    "pasco = Pasco(k, rho, R, solver=solver)\n",
    "partition_pasco = pasco.fit_transform(A)\n",
    "tf = time()\n",
    "\n",
    "print(\"AMI with PASCO+SC : {:5.3f}\".format(ami(partition_pasco, partition_true)))\n",
    "print(\"Computation time: {:5.3f}sec\".format((tf-ti)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bed6b4-9975-4aa2-99ad-f4d1dfe31585",
   "metadata": {},
   "source": [
    "### with extra arguments\n",
    "\n",
    "If arguments, other than `A` and `k`, need to be pass to the function, they can be passed through the `solver_args` arguments as a dictionnary. \\\n",
    "Here is an example where we want to specify which eigen solver to use in SC. We use the function `my_clustering2(A,k,eigen_solver)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51579c84-e6bf-4f1c-b219-d18b0f8fb214",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tutorial_utils import my_clustering2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141f0508-2992-43ff-928c-fedebdd5aeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = my_clustering2 # we use SC to compute the partition of the coarsened graphs.\n",
    "solver_args = {\"eigen_solver\":'lobpcg'}\n",
    "\n",
    "ti = time()\n",
    "pasco = Pasco(k, rho, R, solver=solver, solver_args=solver_args)\n",
    "partition_pasco = pasco.fit_transform(A)\n",
    "tf = time()\n",
    "\n",
    "print(\"AMI with PASCO+SC : {:5.3f}\".format(ami(partition_pasco, partition_true)))\n",
    "print(\"Computation time: {:5.3f}sec\".format((tf-ti)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3353e2be-de92-40ad-aa6d-2f5eed2f4ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
