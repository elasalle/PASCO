{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "626569d5-ba46-49b9-a673-ea8acb24c7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import networkx as nx\n",
    "from pasco.pasco import Pasco\n",
    "from pasco.data_generation import generate_or_import_SBM\n",
    "import numpy as np\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as nmi, adjusted_mutual_info_score as ami, \\\n",
    "    adjusted_rand_score as ari\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac794f8b-4613-4190-ba56-99d6a991541e",
   "metadata": {},
   "source": [
    "# Create a big graph with a community structure"
   ]
  },
  {
   "cell_type": "raw",
   "id": "95a12b70-2454-4370-a9e6-fd211676ff08",
   "metadata": {},
   "source": [
    "Here, we generate a graph from the Stochastic Block Model. We choose parametrize the model using the average degree and the ratio of inside and outside community probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ff54a80-4a9f-4f90-b6b5-80e591881cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph imported\n"
     ]
    }
   ],
   "source": [
    "n = int(1e4) # number of nodes \n",
    "k = 100  # number of communities \n",
    "d = 1.5 # to set the average degree\n",
    "alpha = 1/(2*(k-1)) # ration of probabilities. Here half the conjectured threshold. See Paper. \n",
    "\n",
    "n_k = n//k # number of nodes per community\n",
    "avg_d = d*np.log(n) # average degree\n",
    "pin = avg_d / ((1 + (k-1) *alpha )*n_k) # inside community edge probability\n",
    "pout = alpha * pin # between communities edge probability\n",
    "\n",
    "\n",
    "partition_true = np.array([i for i in range(k) for j in range(n_k)]) # the true nodes partition\n",
    "G = generate_or_import_SBM(n, k, pin, pout, data_folder=\"experiments/data/graphs/SBMs/\", seed=2024)\n",
    "A = nx.adjacency_matrix(G , nodelist=range(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc333627-7484-4711-953e-f67e3167ca47",
   "metadata": {},
   "source": [
    "# Compute PASCO with Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc7e0e68-19b5-4697-bf90-fa0f1b1c6cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMI with PASCO+SC : 0.712\n",
      "Computation time: 8.415sec\n"
     ]
    }
   ],
   "source": [
    "rho = 10 # reduction factor (the coarsened graph will have a size rho times smaller)\n",
    "R = 5 # number of repetitions of the coarsening. R should be kept below the number of CPUs so that all clusterings can be computed in one batch.\n",
    "solver = \"SC\" # we use SC to compute the partition of the coarsened graphs.\n",
    "\n",
    "ti = time()\n",
    "pasco = Pasco(k, rho, R, solver=solver)\n",
    "partition_pasco = pasco.fit_transform(A)\n",
    "tf = time()\n",
    "\n",
    "print(\"AMI with PASCO+SC : {:5.3f}\".format(ami(partition_pasco, partition_true)))\n",
    "print(\"Computation time: {:5.3f}sec\".format((tf-ti)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61db1f40-e6b3-4c10-a575-2b682b1e571d",
   "metadata": {},
   "source": [
    "# How to use PASCO with your own clustering algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae709c91-850e-4751-a0ba-57a4519f80ac",
   "metadata": {},
   "source": [
    "We show here how to use PASCO with a clustering algorithm that would not be implemented in the PASCO package. \\\n",
    "Here we are going to do as if SC was not implemented in PASCO. \n",
    "\n",
    "To do so, we need to create a proxy function. It should take as input a sparse csr_array and potentially a number of clusters $k$ and returns a partition as an array-like. We defined in the `tutorial_utils.py` file a clustering function `my_clustering(A,k)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d2d757d-9ec9-4185-b5ee-ba7e8cb55a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tutorial_utils import my_clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcae116-40c9-4d27-9e72-68ed90920838",
   "metadata": {},
   "source": [
    "Now we can use our function `my_clustering` and pass it to the `solver` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7e01ed3-f14a-48d2-ad56-aa974f713542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMI with PASCO+SC : 0.710\n",
      "Computation time: 8.566sec\n"
     ]
    }
   ],
   "source": [
    "solver = my_clustering # clustering is computed using `my_clustering`\n",
    "\n",
    "ti = time()\n",
    "pasco = Pasco(k, rho, R, solver=solver)\n",
    "partition_pasco = pasco.fit_transform(A)\n",
    "tf = time()\n",
    "\n",
    "print(\"AMI with PASCO+SC : {:5.3f}\".format(ami(partition_pasco, partition_true)))\n",
    "print(\"Computation time: {:5.3f}sec\".format((tf-ti)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bed6b4-9975-4aa2-99ad-f4d1dfe31585",
   "metadata": {},
   "source": [
    "### with extra arguments\n",
    "\n",
    "If arguments, other than `A` and `k`, need to be pass to the function, they can be passed through the `solver_args` arguments as a dictionnary. \\\n",
    "Here is an example where we want to specify which eigen solver to use in SC. We use the function `my_clustering2(A,k,eigen_solver)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51579c84-e6bf-4f1c-b219-d18b0f8fb214",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tutorial_utils import my_clustering2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "141f0508-2992-43ff-928c-fedebdd5aeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMI with PASCO+SC : 0.699\n",
      "Computation time: 8.269sec\n"
     ]
    }
   ],
   "source": [
    "solver = my_clustering2 # we use SC to compute the partition of the coarsened graphs.\n",
    "solver_args = {\"eigen_solver\":'lobpcg'}\n",
    "\n",
    "ti = time()\n",
    "pasco = Pasco(k, rho, R, solver=solver, solver_args=solver_args)\n",
    "partition_pasco = pasco.fit_transform(A)\n",
    "tf = time()\n",
    "\n",
    "print(\"AMI with PASCO+SC : {:5.3f}\".format(ami(partition_pasco, partition_true)))\n",
    "print(\"Computation time: {:5.3f}sec\".format((tf-ti)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3353e2be-de92-40ad-aa6d-2f5eed2f4ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
